{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir(\"../input/intel-image-classification\"))\ndata_dir = \"../input/intel-image-classification\"\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-28T22:54:04.417226Z","iopub.execute_input":"2021-12-28T22:54:04.417854Z","iopub.status.idle":"2021-12-28T22:54:04.425991Z","shell.execute_reply.started":"2021-12-28T22:54:04.417811Z","shell.execute_reply":"2021-12-28T22:54:04.424958Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"!ls ../input/intel-image-classification","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:54:04.837158Z","iopub.execute_input":"2021-12-28T22:54:04.837519Z","iopub.status.idle":"2021-12-28T22:54:05.552095Z","shell.execute_reply.started":"2021-12-28T22:54:04.837483Z","shell.execute_reply":"2021-12-28T22:54:05.551195Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision.datasets import ImageFolder\nimport torch.nn as nn\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import MNIST\nfrom torch.utils.data import random_split\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:54:05.554877Z","iopub.execute_input":"2021-12-28T22:54:05.555777Z","iopub.status.idle":"2021-12-28T22:54:05.561629Z","shell.execute_reply.started":"2021-12-28T22:54:05.555731Z","shell.execute_reply":"2021-12-28T22:54:05.560843Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"# Hyperparmeters\nbatch_size = 128\nlearning_rate = 0.002\nepoch=20\n# Other constants\ninput_size = 128*128\nnum_classes = 10","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:54:06.586143Z","iopub.execute_input":"2021-12-28T22:54:06.586449Z","iopub.status.idle":"2021-12-28T22:54:06.590958Z","shell.execute_reply.started":"2021-12-28T22:54:06.586391Z","shell.execute_reply":"2021-12-28T22:54:06.590155Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"train_dir = data_dir + '/seg_train/seg_train'\ntest_dir = data_dir+ '/seg_test/seg_test'\n\n#classes in dataset:\nclasses = os.listdir(train_dir)\nclasses","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:54:07.746568Z","iopub.execute_input":"2021-12-28T22:54:07.747119Z","iopub.status.idle":"2021-12-28T22:54:07.756741Z","shell.execute_reply.started":"2021-12-28T22:54:07.747080Z","shell.execute_reply":"2021-12-28T22:54:07.755958Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\ntrain_tfms = transforms.Compose([transforms.Resize((150,150)),\n                         transforms.ToTensor(),\n                         transforms.Normalize(*stats,inplace=True)])\n\n# train_tfms = transforms.Compose([transforms.Resize((150,150)),\n#                          transforms.ToTensor(),\n#                          transforms.Normalize(*stats,inplace=True),\n#                          transforms.ToPILImage(),\n#                          transforms.RandomCrop(100, padding=4, padding_mode='reflect'),\n#                          transforms.Resize((150,150)),\n#                          transforms.RandomHorizontalFlip(), \n#                          transforms.ToTensor()])\n\n\ntest_tfms = transforms.Compose([transforms.Resize((150,150)),transforms.ToTensor(), \n                         transforms.Normalize(*stats)])\n\nds = ImageFolder(train_dir, train_tfms)\ntest_ds = ImageFolder(test_dir, test_tfms)\nds_show = ImageFolder(train_dir,transforms.Compose([transforms.Resize((150, 150)), transforms.ToTensor()]))\n\nds","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:54:54.497172Z","iopub.execute_input":"2021-12-28T22:54:54.497471Z","iopub.status.idle":"2021-12-28T22:54:56.426181Z","shell.execute_reply.started":"2021-12-28T22:54:54.497436Z","shell.execute_reply":"2021-12-28T22:54:56.425471Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:55:00.013948Z","iopub.execute_input":"2021-12-28T22:55:00.014488Z","iopub.status.idle":"2021-12-28T22:55:00.022976Z","shell.execute_reply.started":"2021-12-28T22:55:00.014451Z","shell.execute_reply":"2021-12-28T22:55:00.022170Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"matplotlib.rcParams['figure.facecolor'] = '#ffffff'\ndef show_example(img, label):\n    print('Label: ', ds_show.classes[label], \"(\"+str(label)+\")\")\n    plt.imshow(img.permute(1, 2, 0))\n\nimg, label = ds_show[8555]\nprint(img.shape, label)\n\nshow_example(*ds_show[8555])\nplt.show()\nshow_example(*ds[8555])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:55:00.927042Z","iopub.execute_input":"2021-12-28T22:55:00.927478Z","iopub.status.idle":"2021-12-28T22:55:01.585901Z","shell.execute_reply.started":"2021-12-28T22:55:00.927429Z","shell.execute_reply":"2021-12-28T22:55:01.585208Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"random_seed=2021;\ntorch.manual_seed(random_seed);\nval_size=4000\ntrain_size=len(ds)-val_size\ntrain_ds,val_ds=random_split(ds,[train_size,val_size])\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True)\nval_dl = DataLoader(valid_ds, batch_size*2)\n\nval_dl","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:55:07.012006Z","iopub.execute_input":"2021-12-28T22:55:07.012562Z","iopub.status.idle":"2021-12-28T22:55:07.022037Z","shell.execute_reply.started":"2021-12-28T22:55:07.012520Z","shell.execute_reply":"2021-12-28T22:55:07.021286Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n        super(Block, self).__init__()\n        self.expansion = 1\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n        self.relu = nn.ReLU()\n        self.identity_downsample = identity_downsample\n\n    def forward(self, x):\n        identity = x\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        if self.identity_downsample is not None:\n            identity = self.identity_downsample(identity)\n\n        x += identity\n        x = self.relu(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:55:07.976214Z","iopub.execute_input":"2021-12-28T22:55:07.976685Z","iopub.status.idle":"2021-12-28T22:55:07.986119Z","shell.execute_reply.started":"2021-12-28T22:55:07.976644Z","shell.execute_reply":"2021-12-28T22:55:07.985253Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n    def __init__(self, block, image_channels, num_classes):\n    \n        super(ResNet, self).__init__()\n        self.expansion = 1\n  \n        layers = [3, 4, 6, 3]\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # ResNetLayers\n        self.layer1 = self.make_layers(block, layers[0], intermediate_channels=64, stride=1)\n        self.layer2 = self.make_layers(block, layers[1], intermediate_channels=128, stride=2)\n        self.layer3 = self.make_layers(block, layers[2], intermediate_channels=256, stride=2)\n        self.layer4 = self.make_layers(block, layers[3], intermediate_channels=512, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * self.expansion, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = self.fc(x)\n        return x\n\n    def make_layers(self, block, num_residual_blocks, intermediate_channels, stride):\n        layers = []\n        \n        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels*self.expansion, kernel_size=1, stride=stride),\n                                            nn.BatchNorm2d(intermediate_channels*self.expansion))\n        layers.append(block(self.in_channels, intermediate_channels, identity_downsample, stride))\n        self.in_channels = intermediate_channels * self.expansion # 256\n        for i in range(num_residual_blocks - 1):\n            layers.append(block(self.in_channels, intermediate_channels)) \n        return nn.Sequential(*layers)\n\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n    \ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds)) ","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:55:09.041716Z","iopub.execute_input":"2021-12-28T22:55:09.042160Z","iopub.status.idle":"2021-12-28T22:55:09.063790Z","shell.execute_reply.started":"2021-12-28T22:55:09.042123Z","shell.execute_reply":"2021-12-28T22:55:09.063012Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"def ResNet34(img_channels=3, num_classes=1000):\n    return ResNet(Block, img_channels, num_classes)\n\nmodel = ResNet34(num_classes=6)\n\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:55:10.067617Z","iopub.execute_input":"2021-12-28T22:55:10.068571Z","iopub.status.idle":"2021-12-28T22:55:10.189265Z","shell.execute_reply.started":"2021-12-28T22:55:10.068523Z","shell.execute_reply":"2021-12-28T22:55:10.188450Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"# class ImageModel(nn.Module):\n#     def __init__(self):   \n#         super().__init__()\n#         self.network = nn.Sequential(\n#             nn.Conv2d(3,16,(3,3)),\n#             nn.ReLU(),\n#             nn.Conv2d(16, 16, (3,3)), \n#             nn.ReLU(),\n#             nn.BatchNorm2d(16),\n#             nn.MaxPool2d(3, 3), \n\n#             nn.Conv2d(16, 32, (3,3)), \n#             nn.ReLU(),\n#             nn.Conv2d(32, 32, (3,3)),  \n#             nn.ReLU(),\n#             nn.BatchNorm2d(32),\n#             nn.MaxPool2d(2, 2), \n\n#             nn.Conv2d(32, 64, (3,3)), \n#             nn.ReLU(),\n#             nn.Conv2d(64, 64, (3,3)), \n#             nn.ReLU(),\n#             nn.BatchNorm2d(64),\n#             nn.MaxPool2d(2, 2), \n            \n#             nn.Conv2d(64, 128, (3,3)), \n#             nn.ReLU(),\n#             nn.Conv2d(128, 128, (3,3)), \n#             nn.ReLU(),\n#             nn.BatchNorm2d(128),\n            \n#             nn.Conv2d(128, 256, (3,3), padding='same'), \n#             nn.ReLU(),\n#             nn.Conv2d(256, 256, (3,3), padding='same'),\n#             nn.ReLU(),\n#             nn.BatchNorm2d(256),\n#             nn.MaxPool2d(2, 2),\n#             nn.Dropout(0.4),\n            \n#             nn.Flatten(),\n            \n#             nn.Linear(1024,256),\n#             nn.ReLU(),\n#             nn.BatchNorm1d(256),\n#             nn.Dropout(0.25),\n            \n#             nn.Linear(256,128),\n#             nn.ReLU(),\n#             nn.BatchNorm1d(128),\n#             nn.Dropout(0.25),\n            \n#             nn.Linear(128,64),\n#             nn.ReLU(),\n#             nn.BatchNorm1d(64),\n#             nn.Dropout(0.25),\n            \n#             nn.Linear(64,32),\n#             nn.ReLU(),\n#             nn.BatchNorm1d(32),\n#             nn.Dropout(0.25),\n            \n#             nn.Linear(32,16),\n#             nn.ReLU(),\n#             nn.BatchNorm1d(16),\n#             nn.Dropout(0.4),\n            \n#             nn.Linear(16, 6))\n        \n#     def forward(self, xb):\n#         return self.network(xb)\n\n#     def training_step(self, batch):\n#         images, labels = batch \n#         out = self(images)                  # Generate predictions\n#         loss = F.cross_entropy(out, labels) # Calculate loss\n#         return loss\n    \n#     def validation_step(self, batch):\n#         images, labels = batch \n#         out = self(images)                    # Generate predictions\n#         loss = F.cross_entropy(out, labels)   # Calculate loss\n#         acc = accuracy(out, labels)           # Calculate accuracy\n#         return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n#     def validation_epoch_end(self, outputs):\n#         batch_losses = [x['val_loss'] for x in outputs]\n#         epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n#         batch_accs = [x['val_acc'] for x in outputs]\n#         epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n#         return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n#     def epoch_end(self, epoch, result):\n#         print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n#             epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n    \n# def accuracy(outputs, labels):\n#     _, preds = torch.max(outputs, dim=1)\n#     return torch.tensor(torch.sum(preds == labels).item() / len(preds))    \n   \n\n# model = ImageModel()\n# print(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:55:10.890226Z","iopub.execute_input":"2021-12-28T22:55:10.890712Z","iopub.status.idle":"2021-12-28T22:55:10.899342Z","shell.execute_reply.started":"2021-12-28T22:55:10.890674Z","shell.execute_reply":"2021-12-28T22:55:10.898575Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda')\n\ndef to_device(data, device):\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n    def __iter__(self):\n        for b in self.dl: \n            yield to_device(b, self.device)\n    def __len__(self):\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:55:11.827149Z","iopub.execute_input":"2021-12-28T22:55:11.827428Z","iopub.status.idle":"2021-12-28T22:55:11.835997Z","shell.execute_reply.started":"2021-12-28T22:55:11.827375Z","shell.execute_reply":"2021-12-28T22:55:11.835125Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\nto_device(model, device);","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:55:13.889679Z","iopub.execute_input":"2021-12-28T22:55:13.889936Z","iopub.status.idle":"2021-12-28T22:55:13.916314Z","shell.execute_reply.started":"2021-12-28T22:55:13.889906Z","shell.execute_reply":"2021-12-28T22:55:13.915668Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, optimizer):\n    history = []\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:55:15.789043Z","iopub.execute_input":"2021-12-28T22:55:15.789594Z","iopub.status.idle":"2021-12-28T22:55:15.796954Z","shell.execute_reply.started":"2021-12-28T22:55:15.789552Z","shell.execute_reply":"2021-12-28T22:55:15.796154Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"model = to_device(model, device)\n\noptimizer = torch.optim.Adam(model.parameters(),learning_rate)\n\nreduce = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:55:16.911950Z","iopub.execute_input":"2021-12-28T22:55:16.912458Z","iopub.status.idle":"2021-12-28T22:55:16.925253Z","shell.execute_reply.started":"2021-12-28T22:55:16.912415Z","shell.execute_reply":"2021-12-28T22:55:16.924456Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"evaluate(model, val_dl)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:55:18.811888Z","iopub.execute_input":"2021-12-28T22:55:18.812428Z","iopub.status.idle":"2021-12-28T22:55:25.759004Z","shell.execute_reply.started":"2021-12-28T22:55:18.812371Z","shell.execute_reply":"2021-12-28T22:55:25.758247Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"history = fit(epoch, learning_rate, model, train_dl, val_dl, optimizer)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T22:55:25.768326Z","iopub.execute_input":"2021-12-28T22:55:25.768661Z","iopub.status.idle":"2021-12-28T23:07:58.766976Z","shell.execute_reply.started":"2021-12-28T22:55:25.768617Z","shell.execute_reply":"2021-12-28T23:07:58.766089Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"history2 = fit(5, learning_rate, model, train_dl, val_dl, optimizer) #дообучаем сеть","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:09:24.522922Z","iopub.execute_input":"2021-12-28T23:09:24.523784Z","iopub.status.idle":"2021-12-28T23:12:33.137141Z","shell.execute_reply.started":"2021-12-28T23:09:24.523743Z","shell.execute_reply":"2021-12-28T23:12:33.136411Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"history2 = fit(10, learning_rate, model, train_dl, val_dl, optimizer) #дообучаем сеть","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:25:39.918444Z","iopub.execute_input":"2021-12-28T23:25:39.919054Z","iopub.status.idle":"2021-12-28T23:31:57.456807Z","shell.execute_reply.started":"2021-12-28T23:25:39.919013Z","shell.execute_reply":"2021-12-28T23:31:57.456064Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"def predict_image(img, model):\n    # Convert to a batch of 1\n    xb = to_device(img.unsqueeze(0), device)\n    # Get predictions from model\n    yb = model(xb)\n    # Pick index with highest probability\n    _, preds  = torch.max(yb, dim=1)\n    # Retrieve the class label\n    return ds.classes[preds[0].item()]","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:32:26.889577Z","iopub.execute_input":"2021-12-28T23:32:26.890315Z","iopub.status.idle":"2021-12-28T23:32:26.897930Z","shell.execute_reply.started":"2021-12-28T23:32:26.890274Z","shell.execute_reply":"2021-12-28T23:32:26.897097Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"img, label = test_ds[1000]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', ds.classes[label], ', Predicted:', predict_image(img, model))","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:32:29.273648Z","iopub.execute_input":"2021-12-28T23:32:29.274508Z","iopub.status.idle":"2021-12-28T23:32:29.512768Z","shell.execute_reply.started":"2021-12-28T23:32:29.274459Z","shell.execute_reply":"2021-12-28T23:32:29.512119Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"cls_data = [[],[]]\n\nfor i in range(len(test_ds)):\n    img, label = test_ds[i]\n    prediction = predict_image(img, model)\n    cls_data[0].append(ds.classes[label])\n    cls_data[1].append(prediction)\n\n\nlabels = ['sea','forest','mountain','glacier','buildings','street']\n\n    \nfrom sklearn.metrics import classification_report\n\nprint(classification_report(cls_data[0], cls_data[1]))","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:32:32.895265Z","iopub.execute_input":"2021-12-28T23:32:32.895803Z","iopub.status.idle":"2021-12-28T23:32:58.417091Z","shell.execute_reply.started":"2021-12-28T23:32:32.895761Z","shell.execute_reply":"2021-12-28T23:32:58.415571Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}